# AI Radar — 2025-12-16

## Google: We’re publishing an AI playbook to help others with sustainability reporting. — **Upgraded**
We’re sharing a practical playbook to help organizations streamline and enhance sustainability reporting with AI.Corporate transparency is essential, but navigating frag…

- Category: Model/API  |  Change: Update  |  Tags: ai
- Source: We’re publishing an AI playbook to help others with sustainability reporting. — https://blog.google/outreach-initiatives/sustainability/ai-playbook-sustainability-reporting/

## Google: Gemini provides automated feedback for theoretical computer scientists at STOC 2 — **Upgraded**
Algorithms & Theory

- Category: Model/API  |  Change: Update  |  Tags: ai
- Source: Gemini provides automated feedback for theoretical computer scientists at STOC 2026 — https://research.google/blog/gemini-provides-automated-feedback-for-theoretical-computer-scientists-at-stoc-2026/

## NVIDIA: NVIDIA Acquires Open — **Announced**
NVIDIA today announced it has acquired SchedMD — the leading developer of Slurm, an open-source workload management system for high-performance computing (HPC) and AI — to help strengthen the open-source software ecosystem and drive AI innovation for researchers, developers and enterprises. NVIDIA will continue to develop and distribute Slurm as open-source, vendor-neutral software, making it Read Article

- Category: Model/API  |  Change: New  |  Tags: ai
- Source: NVIDIA Acquires Open-Source Workload Management Provider SchedMD — https://blogs.nvidia.com/blog/nvidia-acquires-schedmd/

## AWS: Checkpointless training on Amazon SageMaker HyperPod — **Upgraded**
In this post, we introduce checkpointless training on Amazon SageMaker HyperPod, a paradigm shift in model training that reduces the need for traditional checkpointing by enabling peer-to-peer state recovery. Results from production-scale validation show 80–93% reduction in recovery time (from 15–30 minutes or more to under 2 minutes) and enables up to 95% training goodput on cluster sizes with thousands of AI accelerators.

- Category: Model/API  |  Change: Update  |  Tags: ai
- Source: Checkpointless training on Amazon SageMaker HyperPod: Production-scale training with faster fault recovery — https://aws.amazon.com/blogs/machine-learning/checkpointless-training-on-amazon-sagemaker-hyperpod-production-scale-training-with-faster-fault-recovery/

## AWS: Adaptive infrastructure for foundation model training with elastic training on S — **Upgraded**
Amazon SageMaker HyperPod now supports elastic training, enabling your machine learning (ML) workloads to automatically scale based on resource availability. In this post, we demonstrate how elastic training helps you maximize GPU utilization, reduce costs, and accelerate model development through dynamic resource adaptation, while maintain training quality and minimizing manual intervention.

- Category: Model/API  |  Change: Update  |  Tags: ai
- Source: Adaptive infrastructure for foundation model training with elastic training on SageMaker HyperPod — https://aws.amazon.com/blogs/machine-learning/adaptive-infrastructure-for-foundation-model-training-with-elastic-training-on-sagemaker-hyperpod/

## AWS: Customize agent workflows with advanced orchestration techniques using Strands A — **Upgraded**
In this post, we explore two powerful orchestration patterns implemented with Strands Agents. Using a common set of travel planning tools, we demonstrate how different orchestration strategies can solve the same problem through distinct reasoning approaches,

- Category: Model/API  |  Change: Update  |  Tags: ai
- Source: Customize agent workflows with advanced orchestration techniques using Strands Agents — https://aws.amazon.com/blogs/machine-learning/customize-agent-workflows-with-advanced-orchestration-techniques-using-strands-agents/

## AWS: Operationalize generative AI workloads and scale to hundreds of use cases with A — **Upgraded**
In this first part of our two-part series, you'll learn how to evolve your existing DevOps architecture for generative AI workloads and implement GenAIOps practices. We'll showcase practical implementation strategies for different generative AI adoption levels, focusing on consuming foundation models.

- Category: Model/API  |  Change: Update  |  Tags: ai
- Source: Operationalize generative AI workloads and scale to hundreds of use cases with Amazon Bedrock – Part 1: GenAIOps — https://aws.amazon.com/blogs/machine-learning/operationalize-generative-ai-workloads-and-scale-to-hundreds-of-use-cases-with-amazon-bedrock-part-1-genaiops/

## AWS: Applying data loading best practices for ML training with Amazon S3 clients — **Upgraded**
In this post, we present practical techniques and recommendations for optimizing throughput in ML training workloads that read data directly from Amazon S3 general purpose buckets.

- Category: Infra  |  Change: Update  |  Tags: ai
- Source: Applying data loading best practices for ML training with Amazon S3 clients — https://aws.amazon.com/blogs/machine-learning/applying-data-loading-best-practices-for-ml-training-with-amazon-s3-clients/

## HuggingFace: CUGA on Hugging Face — **Upgraded**
CUGA on Hugging Face: Democratizing Configurable AI Agents

- Category: Model/API  |  Change: Update  |  Tags: ai
- Source: CUGA on Hugging Face: Democratizing Configurable AI Agents — https://huggingface.co/blog/ibm-research/cuga-on-hugging-face
